# # import os
# # import pandas as pd
# # import numpy as np
# # from datetime import datetime

# # # ì„¤ì •ê°’
# # INPUT_PATH = "./finger_printing/datasets/train_dataset.csv"
# # OUTPUT_DIR = "./finger_printing/datasets/augmented"
# # AUGMENT_RATIO = 2.0  # ì´ 5ë°° ë§Œë“¤ê¸° (ì›ë³¸ 1 + ì¦ê°• 4)
# # NOISE_STD = 3.0  # RSSIì— ì¶”ê°€í•  ë…¸ì´ì¦ˆ í‘œì¤€í¸ì°¨
# # SEED = 42

# # np.random.seed(SEED)

# # # ë°ì´í„° ë¡œë“œ
# # original_df = pd.read_csv(INPUT_PATH)
# # print(f"ğŸ§ª ì›ë³¸ ë°ì´í„° í–‰ ìˆ˜: {len(original_df)}")

# # # Time ê¸°ì¤€ìœ¼ë¡œ ì„¸ì…˜ ê·¸ë£¹í™”
# # grouped = original_df.groupby("Time")
# # all_keys = list(grouped.groups.keys())
# # num_available = len(all_keys)
# # num_augmented_groups = int(num_available * AUGMENT_RATIO)
# # print(f"âœ¨ ì¦ê°•í•  ì„¸ì…˜ ìˆ˜: {num_augmented_groups}")

# # # ì¦ê°•í•  ì„¸ì…˜ ë¬´ì‘ìœ„ ì„ íƒ (ì¤‘ë³µ í—ˆìš©)
# # sampled_keys = np.random.choice(
# #     all_keys, size=num_augmented_groups, replace=True)

# # augmented_list = []
# # # new_time_start = max(original_df["Time"]) + 1
# # # new_time_start = original_df["Time"].astype(int).max() + 1
# # # datetime â†’ timestamp (ì´ˆ ë‹¨ìœ„ ì •ìˆ˜)
# # original_df["Time"] = pd.to_datetime(original_df["Time"])
# # original_df["Time"] = original_df["Time"].astype(np.int64) // 10**9  # ì´ˆ ë‹¨ìœ„ë¡œ ë³€í™˜

# # new_time_start = original_df["Time"].max() + 1

# # for i, key in enumerate(sampled_keys):
# #     session = grouped.get_group(key).copy()

# #     # RSSIì— ì •ê·œë¶„í¬ ë…¸ì´ì¦ˆ ì¶”ê°€
# #     session["RSSI"] = session["RSSI"] + \
# #         np.random.normal(0, NOISE_STD, size=len(session))

# #     # Time ê°’ ìƒˆë¡œ ë¶€ì—¬ (ê²¹ì¹˜ì§€ ì•Šê²Œ)
# #     session["Time"] = new_time_start + i
# #     augmented_list.append(session)

# # # ì¦ê°• ë°ì´í„° ë³‘í•© ë° ì €ì¥
# # augmented_df = pd.concat(augmented_list, ignore_index=True)
# # final_df = pd.concat([original_df, augmented_df], ignore_index=True)
# # print(f"ì¦ê°• í›„ ì´ ë°ì´í„° í–‰ ìˆ˜: {len(final_df)}")

# # # ì €ì¥
# # timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
# # output_path = os.path.join(
# #     OUTPUT_DIR, f"wifi_rssi_log_augmented_{timestamp}.csv")
# # final_df.to_csv(output_path, index=False, encoding="utf-8")
# # print(f"ì €ì¥ ì™„ë£Œ: {output_path}")

# import os
# import pandas as pd
# import numpy as np
# from datetime import datetime

# # ì„¤ì •ê°’
# INPUT_PATH = "./finger_printing/datasets/train_dataset.csv"
# OUTPUT_DIR = "./finger_printing/datasets/augmented"
# AUGMENT_COUNT = 2  # ì›ë³¸ ëŒ€ë¹„ ì¶”ê°€ë¡œ ëª‡ ë°° ìƒì„±í• ì§€ (2ë©´ â†’ ì´ 3ë°°)
# NOISE_STD = 3.0
# SEED = 42

# np.random.seed(SEED)

# # ì›ë³¸ ë°ì´í„° ë¡œë“œ
# original_df = pd.read_csv(INPUT_PATH)
# print(f"ğŸ§ª ì›ë³¸ ë°ì´í„° í–‰ ìˆ˜: {len(original_df)}")

# # Time ì •ìˆ˜ timestampë¡œ ë³€í™˜
# original_df["Time"] = pd.to_datetime(original_df["Time"])
# original_df["Time"] = original_df["Time"].astype(np.int64) // 10**9

# # ì‹œì‘ íƒ€ì„ ì„¤ì • (ì›ë³¸ max Time ë‹¤ìŒë¶€í„°)
# new_time_start = original_df["Time"].max() + 1

# # ì¦ê°• ë°ì´í„° ìƒì„±
# augmented_list = []
# for i in range(AUGMENT_COUNT):
#     session = original_df.copy()
#     session["RSSI"] = session["RSSI"] + np.random.normal(0, NOISE_STD, size=len(session))
#     session["Time"] = new_time_start + i  # ì¦ê°•ë³¸ì€ ê°™ì€ ì‹œê°„ê°’ì„ ê³µìœ 
#     augmented_list.append(session)

# # ë³‘í•© ë° ì €ì¥
# augmented_df = pd.concat(augmented_list, ignore_index=True)
# final_df = pd.concat([original_df, augmented_df], ignore_index=True)
# print(f"âœ¨ ìµœì¢… ë°ì´í„° í–‰ ìˆ˜: {len(final_df)}")

# # ì €ì¥
# timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
# output_path = os.path.join(OUTPUT_DIR, f"wifi_rssi_augmented_{timestamp}.csv")
# final_df.to_csv(output_path, index=False, encoding="utf-8")
# print(f"ğŸ“ ì €ì¥ ì™„ë£Œ: {output_path}")

import os
import pandas as pd
import numpy as np
from datetime import datetime

# ì„¤ì •ê°’
INPUT_PATH = "./finger_printing/datasets/train_dataset.csv"
OUTPUT_DIR = "./finger_printing/datasets/"
AUGMENT_COUNT = 2  # ì›ë³¸ ëŒ€ë¹„ ì¶”ê°€ë¡œ ëª‡ ë°° ìƒì„±í• ì§€
NOISE_STD = 3.0
DROP_RATIO = 0.1  # ê° ì„¸ì…˜ë³„ 10% dropout
SEED = 42

np.random.seed(SEED)

# ì›ë³¸ ë°ì´í„° ë¡œë“œ
original_df = pd.read_csv(INPUT_PATH)
print(f"ğŸ§ª ì›ë³¸ ë°ì´í„° í–‰ ìˆ˜: {len(original_df)}")

# Time â†’ ì •ìˆ˜ timestamp
original_df["Time"] = pd.to_datetime(original_df["Time"])
original_df["Time"] = original_df["Time"].astype(np.int64) // 10**9

# ì¦ê°•ìš© ì‹œì‘ íƒ€ì„
new_time_start = original_df["Time"].max() + 1

# ì¦ê°• ë°ì´í„° ìƒì„±
augmented_list = []
for i in range(AUGMENT_COUNT):
    session = original_df.copy()

    # ë…¸ì´ì¦ˆ ì¶”ê°€
    session["RSSI"] = session["RSSI"] + np.random.normal(0, NOISE_STD, size=len(session))

    # 10% ë¬´ì‘ìœ„ dropout
    drop_indices = np.random.choice(session.index, size=int(len(session) * DROP_RATIO), replace=False)
    session = session.drop(index=drop_indices).reset_index(drop=True)

    # ìƒˆë¡œìš´ timestamp ë¶€ì—¬
    session["Time"] = new_time_start + i

    augmented_list.append(session)

# ë³‘í•© ë° ì €ì¥
augmented_df = pd.concat(augmented_list, ignore_index=True)
final_df = pd.concat([original_df, augmented_df], ignore_index=True)
print(f"âœ¨ ìµœì¢… ë°ì´í„° í–‰ ìˆ˜: {len(final_df)}")

# ì €ì¥
os.makedirs(OUTPUT_DIR, exist_ok=True)
timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
output_path = os.path.join(OUTPUT_DIR, f"train_dataset_augmented.csv")
final_df.to_csv(output_path, index=False)
print(f"ğŸ“ ì €ì¥ ì™„ë£Œ: {output_path}")