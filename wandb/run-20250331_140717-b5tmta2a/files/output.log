[34m[1mwandb[0m: [33mWARNING[0m Config item 'embedding_dim' was locked by 'sweep' (ignored update).
[34m[1mwandb[0m: [33mWARNING[0m Config item 'transformer_heads' was locked by 'sweep' (ignored update).
[34m[1mwandb[0m: [33mWARNING[0m Config item 'transformer_layers' was locked by 'sweep' (ignored update).
[34m[1mwandb[0m: [33mWARNING[0m Config item 'dropout_rate' was locked by 'sweep' (ignored update).
[34m[1mwandb[0m: [33mWARNING[0m Config item 'batch_size' was locked by 'sweep' (ignored update).
[34m[1mwandb[0m: [33mWARNING[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).
[34m[1mwandb[0m: [33mWARNING[0m Config item 'scheduler' was locked by 'sweep' (ignored update).
[34m[1mwandb[0m: [33mWARNING[0m Config item 'early_stopping' was locked by 'sweep' (ignored update).
[34m[1mwandb[0m: [33mWARNING[0m Config item 'epochs' was locked by 'sweep' (ignored update).
[34m[1mwandb[0m: [33mWARNING[0m Config item 'data_path' was locked by 'sweep' (ignored update).
[34m[1mwandb[0m: Ctrl + C detected. Stopping sweep.
Traceback (most recent call last):
  File "/Users/gichanpark/Desktop/castone_design/finger_printing/train_CNNTransformer_sweep.py", line 181, in train_model
    loss = criterion(outputs, labels_batch)
  File "/opt/homebrew/anaconda3/envs/capstone/lib/python3.8/site-packages/torch/_tensor.py", line 492, in backward
    torch.autograd.backward(
  File "/opt/homebrew/anaconda3/envs/capstone/lib/python3.8/site-packages/torch/autograd/__init__.py", line 251, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
Exception
